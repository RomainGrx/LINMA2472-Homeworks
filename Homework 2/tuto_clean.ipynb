{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n",
      "Hello world\n",
      "['Hello', 'world']\n",
      "['hello', 'world']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "import string\n",
    "\n",
    "stemmer = LancasterStemmer()\n",
    "tbl = str.maketrans({key:None for key in string.punctuation})\n",
    "\n",
    "def remove_punctuation(txt:str) -> str:\n",
    "    return txt.translate(tbl)\n",
    "\n",
    "def tokenize(txt:str):\n",
    "    return nltk.word_tokenize(txt)\n",
    "\n",
    "def stem(token):\n",
    "    return [stemmer.stem(w.lower()) for w in token]\n",
    "\n",
    "ex = \"Hello world!\"\n",
    "print(ex)\n",
    "ex = remove_punctuation(ex)\n",
    "print(ex)\n",
    "ex = tokenize(ex)\n",
    "print(ex)\n",
    "ex = stem(ex)\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "see\n"
     ]
    }
   ],
   "source": [
    "s = LancasterStemmer()\n",
    "\n",
    "print(s.stem('seeing'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hello dear \n<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n    Tom\n    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n</mark>\n, how are you my friend ?</div></span>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Hello dear Tom, how are you my friend ?\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.sentiment)\n",
    "\n",
    "displacy.render(doc, style = \"ent\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I  ->  -PRON-  :: \n",
      "live  ->  live  :: \n",
      "in  ->  in  :: \n",
      "the  ->  the  :: \n",
      "usa  ->  usa  :: \n",
      "We  ->  -PRON-  :: \n",
      "are  ->  be  :: \n",
      "living  ->  live  :: \n",
      "in  ->  in  :: \n",
      "the  ->  the  :: \n",
      "US  ->  US  :: \n",
      "GPE\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "t = nlp(\"I live in the usa! We are living in the US\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for token in t:\n",
    "    #print(token.text,\" -> \", lemmatizer.lemmatize(token.text))\n",
    "    if token.lemma_ not in string.punctuation:\n",
    "        print(token.text,\" -> \", token.lemma_, \" :: \")\n",
    "for ent in t.ents:\n",
    "    print(ent.label_)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.lang.en.English'>\n"
     ]
    }
   ],
   "source": [
    "print(type(nlp))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from spacy.tokens.token import Token\n",
    "from spacy.tokens.doc import Doc\n",
    "from typing import List, Iterable\n",
    "from functools import partial\n",
    "\n",
    "def tokenize(sentence : str, spacy_model) -> Doc:\n",
    "    return spacy_model(sentence)\n",
    "\n",
    "def lemmatize(tokens:Doc, to_avoid:Iterable) -> List[str]:\n",
    "    returned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in to_avoid and token.lemma_ not in to_avoid:\n",
    "            returned_tokens.append(token.lemma_)\n",
    "    return returned_tokens\n",
    "\n",
    "def sent_preprocess(sentence:str, spacy_model, to_avoid:Iterable) -> List[str]:\n",
    "    pipe = (partial(tokenize, spacy_model=spacy_model),\n",
    "            partial(lemmatize, to_avoid=to_avoid))\n",
    "    x = sentence\n",
    "    for f in pipe:\n",
    "        x = f(x)\n",
    "    return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p', 'r', 'o', 'u', 't']\n"
     ]
    }
   ],
   "source": [
    "x = list(\"prout\")\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}