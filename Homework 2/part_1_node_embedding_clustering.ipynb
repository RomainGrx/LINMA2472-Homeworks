{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit",
   "display_name": "Python 3.8.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "56297cd0229b57c2ab24c9ec50848a7d86f74b08e1a4202a6e24fa79bb3d45be"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from characters_real_names import *\n",
    "\n",
    "import re\n",
    "import spacy\n",
    "from spacy.tokens import Span\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Used to get the gender and distinct people with same family noun. \n",
    "\n",
    "def get_person_title(span):\n",
    "    if span.label_ == \"PERSON\" and span.start != 0:\n",
    "        prev_token = span.doc[span.start - 1]\n",
    "        if prev_token.text in (\"Mr\", \"Mr.\", \"Mrs\", \"Mrs.\"):\n",
    "            return prev_token.text + \" \"\n",
    "    return \"\"\n",
    "\n",
    "Span.set_extension(\"person_title\", getter=get_person_title, force=True)\n",
    "\n",
    "book = open(\"../Homework 1/Harry Potter and the Sorcerer.txt\").read()\n",
    "\n",
    "book_chapters = re.split(r'CHAPTER [\\w+]+', book, flags=re.IGNORECASE)[1:]\n",
    "book_chapters[-1] = book_chapters[-1].split(\"THE END\")[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp(''.join(book_chapters))\n",
    "all_sentences = [sent.text.strip() for sent in docs.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "7267it [00:55, 130.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 7267 iterations\n",
    "for i,sentence in tqdm(enumerate(all_sentences)):\n",
    "    doc = nlp(sentence)\n",
    "    entities = [dict(title=ent._.person_title,name=ent.text,position=(ent.start,ent.end)) for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "\n",
    "    for entity in entities:\n",
    "\n",
    "        if entity.get('name') in all_real_names.keys(): continue\n",
    "        for real,check in all_real_names.items():\n",
    "            if entity.get('title') + entity.get('name') in check: \n",
    "                all_sentences[i] = sentence.replace(entity.get('name'), real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 7267/7267 [00:00<00:00, 53973.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_tags     \n",
    "from gensim.parsing.preprocessing import strip_short      \n",
    "from gensim.parsing.preprocessing import strip_multiple_whitespaces\n",
    "from gensim.parsing.preprocessing import stem_text\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from gensim.parsing.preprocessing import strip_punctuation, strip_non_alphanum\n",
    "\n",
    "# select the filters you wish to apply here\n",
    "CUSTOM_FILTERS = [lambda x: x.lower(), strip_non_alphanum, remove_stopwords, strip_multiple_whitespaces]\n",
    "\n",
    "all_sentences_preprocessed = []\n",
    "for sent in tqdm(all_sentences):\n",
    "    parsed_line = preprocess_string(sent, CUSTOM_FILTERS)\n",
    "    all_sentences_preprocessed.append(parsed_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['mr',\n",
       " 'mrs',\n",
       " 'petunia',\n",
       " 'dursley',\n",
       " 'number',\n",
       " 'privet',\n",
       " 'drive',\n",
       " 'proud',\n",
       " 'perfectly',\n",
       " 'normal',\n",
       " 'thank']"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "all_sentences_preprocessed[0]"
   ]
  }
 ]
}